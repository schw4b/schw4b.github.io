[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Simon Schwab",
    "section": "",
    "text": "I’m a coffee and data junkie, that’s all."
  },
  {
    "objectID": "index.html#qualifications",
    "href": "index.html#qualifications",
    "title": "Simon Schwab",
    "section": "Qualifications",
    "text": "Qualifications\nGradStat—Graduate Statistician\nRoyal Statistical Society, 2023\nCAS—Advanced Statistical Data Science\nUniversity of Bern, 2022\nPhD—Health Science\nUniversity of Bern, 2013\nMSc—Psychology, Statistics & Computer Science\nUniversity of Bern, 2008"
  },
  {
    "objectID": "index.html#experiences",
    "href": "index.html#experiences",
    "title": "Simon Schwab",
    "section": "Experiences",
    "text": "Experiences\nSenior Statistician\nSwisstransplant, Bern\n11/2021—Present\nPostdoctoral Researcher\nDepartment of Biostatistics, University of Zurich\n08/2018—09/2021\nResearch Fellow\nBig Data Institute, University of Oxford\n07/2017—06/2018\nVisiting Scientist\nDepartment of Statistics, University of Warwick\n01/2016—06/2017\nResearch Assistant\nUniversity Hospital of Psychiatry, Bern\n10/2008—12/2015"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "KIDMO is a clinical prediction model for the prognosis in kidney transplant recipients at the time of organ offer. It will support decision-making to better understand donor, recipient, and transplant-related risks. The model is currently developed with data from over 2,000 kidney transplant recipients.\n\n\n\nFigure: Schematic overview of the KIDMO multivariable prediction model.\n\n\n\n\n\nStudy registration on OSF Registries from 1. September 2022\nThe online risk calculator is available at https://swtdata.org/kidmo/\nPoster presentation at the ISCB44 in Milano\n\n\n\n\nSchwab S, Sidler D, Haidar F, Kuhn C, Schaub S, Koller M, et al. Clinical prediction model for prognosis in kidney transplant recipients (KIDMO): study protocol. Diagn Progn Res. 2023;7: 6. doi:10.1186/s41512-022-00139-5"
  },
  {
    "objectID": "projects.html#kidmokidney-prediction-model",
    "href": "projects.html#kidmokidney-prediction-model",
    "title": "Projects",
    "section": "",
    "text": "KIDMO is a clinical prediction model for the prognosis in kidney transplant recipients at the time of organ offer. It will support decision-making to better understand donor, recipient, and transplant-related risks. The model is currently developed with data from over 2,000 kidney transplant recipients.\n\n\n\nFigure: Schematic overview of the KIDMO multivariable prediction model.\n\n\n\n\n\nStudy registration on OSF Registries from 1. September 2022\nThe online risk calculator is available at https://swtdata.org/kidmo/\nPoster presentation at the ISCB44 in Milano\n\n\n\n\nSchwab S, Sidler D, Haidar F, Kuhn C, Schaub S, Koller M, et al. Clinical prediction model for prognosis in kidney transplant recipients (KIDMO): study protocol. Diagn Progn Res. 2023;7: 6. doi:10.1186/s41512-022-00139-5"
  },
  {
    "objectID": "projects.html#examex-vivo-allograft-monitoring",
    "href": "projects.html#examex-vivo-allograft-monitoring",
    "title": "Projects",
    "section": "2. EXAM—Ex vivo allograft monitoring",
    "text": "2. EXAM—Ex vivo allograft monitoring\nEXAM is an analytics dashboard for analyzing hypothermic machine perfusion data in deceased-donor kidney transplantation.\n\n\n\nFigure: EXAM analytics dashboard.\n\n\n\nResources\n\nEXAM online dashboard\nGitHub code repository\nTalk at R/Basel 2023 (Video)\n\n\n\nPublications\nSchwab S, Steck H, Binet I, Elmer A, Ender W, Franscini N, et al. EXAM: Ex vivo allograft monitoring dashboard for the analysis of hypothermic machine perfusion data in deceased-donor kidney transplantation. Research Square. 2023. doi:10.21203/rs.3.rs-2713168/v1"
  },
  {
    "objectID": "projects.html#waitwaiting-list-analysis-in-transplantation",
    "href": "projects.html#waitwaiting-list-analysis-in-transplantation",
    "title": "Projects",
    "section": "3. WAIT—Waiting list analysis in transplantation",
    "text": "3. WAIT—Waiting list analysis in transplantation\nMedian waiting times published by transplant organizations around the world may be biased when death or censoring is disregarded. Competing risk multistate models are suited for the analysis of time-to-event data of the organ waiting list. Resulting cumulative incidences are probabilities for transplantation or death by a given time and are a more accurate description of the events occurring on the waiting list. In accordance with the concept of median survival time in survival analysis in clinical trials, we can derive the median time to transplantation (MTT), the waiting time duration at which the transplant probability is 0.50.\n\n\n\nFigure: Cumulative incidence curves for transplantation for the different organs A—E with 95% confidence bands and median time to transplantation (MTT) defined as the duration corresponding to the cumulative incidence of 0.50 (dashed line).\n\n\n\nPublications\nSchwab S, Elmer A, Sidler D, Straumann L, Stuerzinger U, Immer F. Selection bias in reporting of median waiting times in organ transplantation. medRxiv. 2023. p. 2023.12.13.23299859. doi:10.1101/2023.12.13.23299859"
  },
  {
    "objectID": "projects.html#reportreporting-and-evaluation-of-prediction-models-in-organ-transplantation",
    "href": "projects.html#reportreporting-and-evaluation-of-prediction-models-in-organ-transplantation",
    "title": "Projects",
    "section": "4. REPORT—Reporting and evaluation of prediction models in organ transplantation",
    "text": "4. REPORT—Reporting and evaluation of prediction models in organ transplantation\nClinical prediction models for prognosis can predict outcomes and support decision-making. Previous research criticized the quality of prediction models concerning poor reporting and the risk of bias. How this applies to prediction models in organ donation and transplantation needs to be clarified. Therefore, this scoping review aims to assess prediction models used in transplant centers in Switzerland and update clinicians on the transparency, quality of reporting, and risk of bias of these tools.\n\n\n\nFigure: To transplant or not to transplant? Assessing the quality and limitations of existing prediction models can inform further research to develop novel or update existing models to improve the decision-making at transplant centers.\n\n\n\nResources\n\nStudy registration on OSF Registries from 6. April 2024"
  },
  {
    "objectID": "projects.html#projects-as-a-statistical-consultant",
    "href": "projects.html#projects-as-a-statistical-consultant",
    "title": "Projects",
    "section": "Projects as a statistical consultant",
    "text": "Projects as a statistical consultant\n\nHôpitaux Universitaires Genève (HUG)\nDonation-after-circulatory death liver transplantation. Outcomes and risk factors for graft loss and ischemic cholangiopathy in the Swiss setting.\nUniversitäts-Kinderspital Zürich\nPrediction of the serum creatinine after kidney transplantation in children.\nKantonsspital St. Gallen (KSSG)\nOutcome of dual kidney transplantation in Switzerland—a national cohort study.\nUniversity Hospital Zürich (USZ)\nDifferences between the observed and expected serum creatinine range after kidney transplantation."
  },
  {
    "objectID": "posts/fake/index.html",
    "href": "posts/fake/index.html",
    "title": "Fake plastic trees",
    "section": "",
    "text": "Where, oh, where would we researchers be without statistics? It enables us to analyze and report our study findings. Statistics add meaning to the data, creating information and value. Without statistics, data have only minimal meaning.\n“You can be rich in data but poor in information.” —Stephen Senn\nMy personal view, which is perhaps a little bit extreme, is that all data are rubbish without statistics. Nevertheless, the glorification of data has evolved drastically over the last decade and continues to do so. An example is the front cover of the magazine Science from 2011. It is a collage of words, but only one stands out in large letters: “data.”\nWe are indeed very hungry for data. However, I don’t believe data should take center stage. What is more important is how we perform statistics on the data.\nI tried to find the word “statistics” on the front cover but could not find it. Can you see it? Maybe Science should have made the word “data” a bit smaller to leave more room for the word “statistics,” the discipline that concerns the collection, organization, analysis, interpretation, and presentation of data.\nNevertheless, many medical studies are conducted with little or no involvement of adequately trained statisticians; and the same is true for scientific peer-review [1]. Statisticians are often only involved at the end of a study to analyze the data despite the fact that their are specialists in helping clinicians clarify the question and designing the study from scratch. Often, research projects do not include enough funding for statistical work.\nIt seem that data is largely overvalued and statistics is largely undervalued.\n\n\n\nScience magazine front cover from 11. February 2011.\n\n\n\nBig data\nAnother example of the glorification of data is the term Big Data.\nWhat does big data even mean? Maybe big data is not the latest advancement of biomedicine in tackling unsolved problems. Instead, it is our defeat against data-hungry methods from machine learning, a hyped discipline also known as artificial intelligence or simply “AI.” For example, 4,000 biomarkers times 200 patients is not big data; the sample size is still N=200, and I consider this a small study. For a prediction model for prognosis, for example, I would instead prefer 4 clinically relevant variables from 2,000 patients, even though this reflects only 1% of the data in the former example. Don’t be too impressed by the width of a data set, it may backfire as we will see.\nToo much data can make data analysis harder, but this is often unrecognized. The unsystematic collection of high-dimensional data, when data is more “wide” than “long,” can lead to more questions than answers. For example, the failure of protein cancer biomarker research [2] or the failure of the Human Brain Project [3]. Maybe the combination of big data and overhyped promises is a reason for concern.\nWhat I am trying to say is that data alone does not represent any real value, even if it is big data. Data can’t speak for themselves. Data is pretty dumb. Think about your favorite restaurant and your favorite dish. Imagine being served only unprepared food, raw and uncooked. That’s what data is basically without statistics; it’s just the ingredients, the parts. Data on their own are inedible food. And when you get plenty of it, it does not turn things for the better.\nOne may object that more data will always lead to less uncertainty. This is, in principle, true. However, then I imagine the many attempts very large datasets are being explored, analyzed, and reanalyzed until the the desired result is obtained, or until the model fits the data. Then, this process only appears to reduce the uncertainty.\nIt is called phantom degrees of freedom [4]; we can’t see them, but they are there. It is one of the may ways the dark statistics deceive us. We have reduced uncertainty through a very well-fitting model, but this is an illusion because, in reality, the process by which the data were analyzed has increased uncertainty. The standard errors and p-values lie to us; they are only valid if we don’t torture the data too much.\n\n\nBrave new tools\nStatistics summarize data into eatable bites. However, statistical data analysis is not something that can be prepared quickly and easily like a microwave-ready meal. It requires specialist work. And yes, mistakes can be made in this process [5]. Why can’t AI do all the difficult work for us?\nStatistical software from past times tried to create the illusion that a nice graphical interface can enable statistics at the push of a button. The exact opposite has happened with the R programming language. We moved away from pressing buttons to writing code, which is, as a side effect, easier to reproduce.\nI recently discovered a website with another attempt to make statistics easy: an AI-powered statistics tool.\n“It makes complex data analytics accessible to anyone, eliminating the need for advanced technical knowledge or expertise.” —from a website about an AI-based statistics tool\nHow does it work? I don’t know. You simply chat with your data files? For me, it sounds more like the production of flawed conclusions by untrained people via dangerous tools. That will be the gloomy future, it seems.\nThe production of science fiction as science facts.\nIronically, the tool has the same name as an assassinated Roman emperor. This is not a very good omen for the tool, isn’t it? Maybe we are all going to be very disappointed with AI doing our statistical analyses.\nMaybe, just maybe, AI sucks at being a personal statistical assistant. Maybe AI is much better at misusing statistics. The perfect p-hacking machine. AI is misused in many ways to produce fake images, fake texts, fake human voices, and fake videos. Why not fake statistics? AI confuses the real with the unreal, and why can’t this also be applied to scientific data? The perfect tool for data fabrication in the future. Or as Cathy O’Neil said, a new weapon of math destruction [6].\nIn the future, I think we will need more people like Elisabeth Bik. People who are trained to spot fake research [7].\n\n\nWhat lies ahead of us?\nNowadays, AI and machine learning are heavily promoted to “revolutionize healthcare”; this seems an overhyped claim given the notorious overfitting of data in the field [8]. To be fair, it is not just AI that baffles me. Recently, 246 biologists obtained different results from the same data [9] or the latest blunder in functional MRI research [10]. This all demonstrates that we researchers seem to learn a lot from the noise in the data.\nFor now, I want to say that whenever there is a novel, exciting claim, my first reaction is often very reserved. I usually don’t believe it when I see some red flags.\nNow, are you ready for what is next? A world where the relentless rush of technology blurs the lines between what’s real and what’s not?\nA world of fake plastic trees?\n\n\nJust one more thing\nLet’s perform a simulation to highlight the challenges with wide data. First, I create data with many patients and few variables (long data). Then, I generate some high-dimensional data with many more variables than patients (wide data).\nBut first I need to write a short function tidy_lm() for a tidy output from a linear regression model; this is just cosmetics.\n\n\nCode\n# helper function for lm output\ntidy_lm &lt;- function(fit) {\n  \n  sfit = summary(fit)\n  lower = confint(fit)[,1]\n  upper = confint(fit)[,2]\n  betas = coef(fit)\n  effect = sprintf(\"%.2f (from %.2f to %.2f)\", betas, lower, upper)\n  \n  tab = data.frame(effect = effect,\n                   pvalue = swt::tidy_pvalues(sfit$coefficients[,4]))\n  \n  colnames(tab) = c(\"Effect (95% CI)\", \"p-value\")\n  return(tab)\n}\n\n\n\nLong data\nI simulate data for \\(N\\) = 2,000 patients and \\(q\\) = 4 variables. I assume the three prognostic variables (\\(x_1\\), \\(x_2\\), and \\(x_3\\)) are uncorrelated and strongly related to the outcome using an additive model. The true effects are \\(\\beta_1\\) = 0.5, \\(\\beta_2\\) = 0.3, \\(\\beta_3\\) = 0.2. For the unrelated variable \\(x_4\\) we have \\(\\beta_4\\) = 0. I added some noise so that the explained variance is about 20% (adjusted \\(R^2\\)).\n\n\nCode\nset.seed(2024)\n\nSNR = 0.65 # corresponds to 20% explained variance R^2\nN = 2000 # number of patients\nq = 4 # number of predictors\n\n# generate data for a study\ndata = array(rnorm(N*q), dim = c(N, q))\nnoise = rnorm(N) # generate standard normal errors\ny = 0.5*data[,1] + 0.3*data[,2] + 0.2*data[,3] + 1/sqrt(SNR)*noise\n\nd = data.frame(y = y, x1 = data[,1], x2 = data[,2], x3 = data[,3], x4 = data[,4])\nfit = lm(y ~ x1 + x2 + x3 + x4, data = d)\ntidy_lm(fit)\n\n\n\n\n\n\n\nEffect (95% CI)\np-value\n\n\n\n\n(Intercept)\n0.00 (from -0.05 to 0.06)\n0.96\n\n\nx1\n0.49 (from 0.43 to 0.54)\n&lt; 0.001 ***\n\n\nx2\n0.31 (from 0.25 to 0.37)\n&lt; 0.001 ***\n\n\nx3\n0.23 (from 0.17 to 0.29)\n&lt; 0.001 ***\n\n\nx4\n-0.01 (from -0.07 to 0.04)\n0.67\n\n\n\n\n\n\nWe can see that the effect estimates are close to the true effects. The p-values show that the data is very incompatible with our null model (that the true effects are zero). Since I’m the creator of the data and know the truth, I can confirm that we found the correct model (or a very good approximation thereof).\n\n\nWide data\nNow, I increase the amount of data by a factor of 100. However, I’m not increasing the sample size in terms of number of patients; I even decrease the sample size to \\(N\\) = 200. In return, I create data with \\(q\\) = 4,000 biomarkers (high-dimensional data). The simulation is similar as above except the first and last bullet point:\n\nEach study has \\(N\\) = 200 patients \\(\\times\\) \\(q\\) = 4,000 biomarkers\nAll predictors are uncorrelated and normally distributed, i.e. \\(\\mathcal{N}(0,\\,1)\\)\nThe outcome is additive of predictor \\(x_1\\), \\(x_{2}\\), and \\(x_{3}\\)\nThe true effect parameters are \\(\\beta_1\\) = 0.5, \\(\\beta_{2}\\) = 0.3, and \\(\\beta_{3}\\) = 0.2\nFor each biomarker, we estimate a univariable model and use a cutoff of \\(p \\le\\) 0.05 for screening (univariable screening)\n\nNow, I will simulate \\(k\\) = 20 of such studies.\n\n\nCode\nset.seed(2024)\n\nSNR = 0.65\nk = 20 # number of studies\nN = 200 # number of patients\nq = 4000 # number of biomarkers\n\nhas.model = rep(NA, k)\nppv = rep(NA, k)\n\n# pb = txtProgressBar(min = 1, max = k, style = 3)\nfor (j in 1:k) { # iterate across studies\n  \n  # generate data for a study\n  data = array(rnorm(N*q), dim = c(N, q))\n  noise = rnorm(N) # generate standard normal errors\n  y = 0.5*data[,1] + 0.3*data[,2] + 0.2*data[,3] + 1/sqrt(SNR)*noise\n  \n  pvalues = rep(NA, q)\n  for (i in 1:q) { # iterate across biomarkers\n    d = data.frame (y = y, x = data[, i]) # univariable screening\n    fit = lm(y ~ x, data = d)\n    stats = summary(fit)\n    pvalues[i] = stats$coefficients[2,4]\n  }\n  # results of single studies\n  model = which(pvalues &lt;= 0.05) # variable selection\n  has.model[j] = all(c(1, 2, 3) %in% model) # correct biomarkers found\n  # proportion of true biomarkers among all positive biomarkers\n  ppv[j] = sum(c(1, 2, 3) %in% model) / length(model)\n  # setTxtProgressBar(pb, j)\n}\n\n\nLet’s look at the data of one of the 20 studies (the last one), and pretend we knew that \\(x_1\\), \\(x_2\\), and \\(x_3\\) are the relevant biomarkers. The regression results are below.\n\n\nCode\nd = data.frame (y = y, x1 = data[,1], x2 = data[,2], x3 = data[,3])\nfit = lm(y ~ x1 + x2 + x3, data = d)\ntidy_lm(fit)\n\n\n\n\n\n\n\nEffect (95% CI)\np-value\n\n\n\n\n(Intercept)\n-0.18 (from -0.35 to -0.00)\n0.047 *\n\n\nx1\n0.38 (from 0.21 to 0.55)\n&lt; 0.001 ***\n\n\nx2\n0.36 (from 0.19 to 0.54)\n&lt; 0.001 ***\n\n\nx3\n0.33 (from 0.16 to 0.51)\n&lt; 0.001 ***\n\n\n\n\n\n\nThe effect estimates are not very close to the true effects, and the confidence intervals are wider. This is not surprising as the sample size is only \\(N =\\) 200. All in all, we are less certain, but this is not even the main problem.\nThe main problem is we don’t know that \\(x_1\\), \\(x_2\\), and \\(x_3\\) are the relevant biomarkers. Using univariable screening, with \\(p \\le\\) 0.05 for variable selection, only 9 from a total of 20 study results contain the three biomarkers \\(x_1\\), \\(x_{2}\\), and \\(x_{3}\\).\nThere is more bad news. The proportion of biomarkers which are really true from all the biomarkers that were found to be positive (i.e., were seleceted by our screening criterion of p \\(le\\) 0.05) is only 0.01 (range from 0.00 to 0.02); this is also known as the positive predictive value.\nIn our last study study, for example, 3 out of the 3 correct biomarkers were selected; however, a total of 220 variables were selected altogether. Thus, the proportion of true biomarkers form all the biomarkers found to be relevant is only 1.4%.\nSo what does this mean? I tried to find a needle in a haystack. What makes it even more difficult is that there appear to be many fake needles in the haystack.\nI hope I could illustrate what makes the analysis of high-dimensional data extremely difficult. Certainly, there are situations where the problem is not so extreme, but there may be situation where the problem is even more extreme. You may object that the simulations I made could be made differently yielding different results. Maybe yes, but does it matter? We often don’t know how good is the signal-to-nose ratio. And completely ind the dark, we must be very careful in analyzing high-dimensional data.\nIf you are considering biomarker research, maybe a good starting point is the excellent article “How to Do Bad Biomarker Research” by Frank Harrell [11] and it would certainly be a good idea to do a course in high-dimensional data analysis.\nThe title of this post is a song by the band Radiohead. Photo by Frames For Your Heart on Unsplash.\n\n\n\n\n\n\nReferences\n\n1. Van Calster B, Wynants L, Riley RD, Smeden M van, Collins GS. Methodology over metrics: Current scientific standards are a disservice to patients and society. J Clin Epidemiol. 2021;138: 219–226. doi:10.1016/j.jclinepi.2021.05.018\n\n\n2. Diamandis EP. The failure of protein cancer biomarkers to reach the clinic: Why, and what can be done to address the problem? BMC Med. 2012;10: 87. doi:10.1186/1741-7015-10-87\n\n\n3. Yong E. The human brain project hasn’t lived up to its promise. The Atlantic. 2019. \n\n\n4. Harrell FE. Regression modeling strategies. Springer International Publishing; 2015. doi:10.1007/978-3-319-19425-7\n\n\n5. Schwab S, Held L. Statistical programming: Small mistakes, big impacts. Significance. 2021;18: 6–7. doi:10.1111/1740-9713.01522\n\n\n6. O’Neil C. Weapons of math destruction: How big data increases inequality and threatens democracy. 1st ed. Crown; 2016. \n\n\n7. Shen H. Meet this super-spotter of duplicated images in science papers. Nature. 2020;581: 132–136. doi:10.1038/d41586-020-01363-z\n\n\n8. Volovici V, Syn NL, Ercole A, Zhao JJ, Liu N. Steps to avoid overuse and misuse of machine learning in clinical research. Nat Med. 2022;28: 1996–1999. doi:10.1038/s41591-022-01961-6\n\n\n9. Oza A. Reproducibility trial: 246 biologists get different results from same data sets. Nature. 2023;622: 677–678. doi:10.1038/d41586-023-03177-1\n\n\n10. Prillaman M. This fMRI technique promised to transform brain research - why can no one replicate it? Nature. 2024. doi:10.1038/d41586-024-00931-x\n\n\n11. Harrell F. Statistical thinking - how to do bad biomarker research. https://www.fharrell.com/post/badb/; 2022. \n\nCitationBibTeX citation:@misc{schwab2024,\n  author = {Schwab, Simon},\n  title = {Fake Plastic Trees},\n  date = {2024},\n  url = {https://www.statsyup.org/posts/fake/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nSchwab S. Fake plastic trees. 2024. Available:\nhttps://www.statsyup.org/posts/fake/"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "I’m a senior statistician and researcher at Swisstransplant with professional qualifications in statistics and medical research. My main focus at is:\n\nrisk prediction in kidney and liver transplantation (prediction models for prognosis)\nanalysis of the waiting list to estimate probability of transplantation\ndevelopment of methodology for quality control\nstatistical reporting of national transplant activity\n\nI am also a member of the scientific committee of the Swiss Transplant Cohort Study (STCS), and a founding member of the interest group Statistics in Organ Transplantation (SOT). Furthermore, I am a lecturer in biostatistics and good research practice at the Center for Reproducible Science, a competence center of the University of Zurich."
  },
  {
    "objectID": "about.html#professional",
    "href": "about.html#professional",
    "title": "About me",
    "section": "",
    "text": "I’m a senior statistician and researcher at Swisstransplant with professional qualifications in statistics and medical research. My main focus at is:\n\nrisk prediction in kidney and liver transplantation (prediction models for prognosis)\nanalysis of the waiting list to estimate probability of transplantation\ndevelopment of methodology for quality control\nstatistical reporting of national transplant activity\n\nI am also a member of the scientific committee of the Swiss Transplant Cohort Study (STCS), and a founding member of the interest group Statistics in Organ Transplantation (SOT). Furthermore, I am a lecturer in biostatistics and good research practice at the Center for Reproducible Science, a competence center of the University of Zurich."
  },
  {
    "objectID": "about.html#memberships",
    "href": "about.html#memberships",
    "title": "About me",
    "section": "Memberships",
    "text": "Memberships\n\nFellow of the Royal Statistical Society (RSS)\nMember of the Swiss Statistical Society (SSS)\nMember of the International Society for Clinical Biostatistics (ISCB)"
  },
  {
    "objectID": "about.html#private",
    "href": "about.html#private",
    "title": "About me",
    "section": "Private",
    "text": "Private\nI am married and the father of two children (born 2021 and 2023). I enjoy playing guitar and listening to alternative metal and indie rock.\n\n\n\nPearl Jam live in Zurich on 22. June 2022."
  },
  {
    "objectID": "output.html",
    "href": "output.html",
    "title": "Research output",
    "section": "",
    "text": "van Zwet, E., Gelman, A., Greenland, S., Imbens, G., Schwab, S., & Goodman, S. N. (2024). A New Look at P Values for Randomized Clinical Trials. NEJM Evidence, 3(1), EVIDoa2300003. doi:10.1056/EVIDoa2300003\nSchwab, S., & Immer, F. (2023). Prognosemodelle und künstliche Intelligenz. Schweizerische Ärztezeitung. doi:10.4414/saez.2023.1266894718\nSchwab, S., Sidler, D., Haidar, F., Kuhn, C., Schaub, S., Koller, M., Mellac, K., Stürzinger, U., Tischhauser, B., Binet, I., Golshayan, D., Müller, T., Elmer, A., Franscini, N., Krügel, N., Fehr, T., Immer, F., Swisstransplant Kidney Working Group (STAN), & Swiss Transplant Cohort Study. (2023). Clinical prediction model for prognosis in kidney transplant recipients (KIDMO): study protocol. Diagnostic and Prognostic Research, 7(1), 6. doi:10.1186/s41512-022-00139-5\nFor more publications, see Google Scholar and Pubmed."
  },
  {
    "objectID": "output.html#recent-publications",
    "href": "output.html#recent-publications",
    "title": "Research output",
    "section": "",
    "text": "van Zwet, E., Gelman, A., Greenland, S., Imbens, G., Schwab, S., & Goodman, S. N. (2024). A New Look at P Values for Randomized Clinical Trials. NEJM Evidence, 3(1), EVIDoa2300003. doi:10.1056/EVIDoa2300003\nSchwab, S., & Immer, F. (2023). Prognosemodelle und künstliche Intelligenz. Schweizerische Ärztezeitung. doi:10.4414/saez.2023.1266894718\nSchwab, S., Sidler, D., Haidar, F., Kuhn, C., Schaub, S., Koller, M., Mellac, K., Stürzinger, U., Tischhauser, B., Binet, I., Golshayan, D., Müller, T., Elmer, A., Franscini, N., Krügel, N., Fehr, T., Immer, F., Swisstransplant Kidney Working Group (STAN), & Swiss Transplant Cohort Study. (2023). Clinical prediction model for prognosis in kidney transplant recipients (KIDMO): study protocol. Diagnostic and Prognostic Research, 7(1), 6. doi:10.1186/s41512-022-00139-5\nFor more publications, see Google Scholar and Pubmed."
  },
  {
    "objectID": "output.html#r-software",
    "href": "output.html#r-software",
    "title": "Research output",
    "section": "R Software",
    "text": "R Software\n\ncochrane—Import Data from the Cochrane Database of Systematic Reviews (CDSR).\nEXAM—Ex vivo allograft monitoring dashboard.\nswt—Swisstransplant R package."
  },
  {
    "objectID": "output.html#reproducibility-notes",
    "href": "output.html#reproducibility-notes",
    "title": "Research output",
    "section": "Reproducibility Notes",
    "text": "Reproducibility Notes\nA series of commentaries highlight topics related to the production of robust, effective, and reproducible science; see also here.\nSchwab, S., Janiaud, P., Dayan, M., Amrhein, V., Panczak, R., Palagi, P. M., Hemkens, L. G., Ramon, M., Rothen, N., Senn, S., Furrer, E., & Held, L. (2022). Ten simple rules for good research practice. PLoS Computational Biology, 18(6), e1010139. doi:10.1371/journal.pcbi.1010139\nSchwab, S., & Held, L. (2021). Statistical programming: Small mistakes, big impacts. Significance, 18(3), 6–7. doi:10.1111/1740-9713.01522\nHeld, L., Pawel, S., & Schwab, S. (2020). Replication power and regression to the mean. Significance, 17(6), 10–11. doi:10.1111/1740-9713.01462\nSchwab, S., & Held, L. (2020). Science after Covid-19: Faster, better, stronger? Significance, 17(4), 8–9. doi:10.1111/1740-9713.01415\nSchwab, S., & Held, L. (2020). Different worlds Confirmatory versus exploratory research. Significance, 17(2), 8–9. doi:10.1111/1740-9713.01369\nHeld, L., & Schwab, S. (2020). Improving the reproducibility of science. Significance, 17(1), 10–11. doi:10.1111/j.1740-9713.2020.01351.x"
  },
  {
    "objectID": "output.html#presentations",
    "href": "output.html#presentations",
    "title": "Research output",
    "section": "Presentations",
    "text": "Presentations\nA complete list of slides from my presentations is available at OSF.\nTen simple rules for good research practice\nTalk at the Computational Reproducibility Seminar—NEXUS Personalized Health Technologies, ETH Zurich\n16/05/2024\nUnderstanding and managing bias in medical research\nTalk for the Swiss Society for Pneumology—University Hospital of Zurich\n28/03/2024\nEXAM—Ex-vivo allograft monitoring dashboard for deceased-donor kidney transplantation (see also video)\nTalk at R/Basel 2023—Roche Switzerland\n21/06/2023\nAn introduction to R with the Stanford Heart Transplant Data\nTalk at BernR—Bern R user group\n09/12/2021\nFrom regression to machine learning in R (see also video)\nTalk in the seminar Applied Machine Learning in Diagnostic Imaging—University Hospital of Zurich\n15/04/2021"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Fiction, future, and prediction",
    "section": "",
    "text": "My posts will delve into the fascinating topic of data science and statistics in medicine. The posts are always presented in a general context, peppered with personal opinions, and ideally, we’ll explore a compelling data example at the end.\nAlways remember that opinions are the lowest form of evidence in the epidemiologists’ famous pyramid of negligence.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFake plastic trees\n\n\nData are overvalued, and statistics are undervalued. New tools and technologies will likely not revolutionize healthcare but may confuse us about which data and evidence are real and which are not.\n\n\n\nReproducibility\n\n\nDark Statistics\n\n\n\n\n\n\n\n\n\nMay 9, 2024\n\n\nSimon Schwab\n\n\n\n\n\n\nNo matching items"
  }
]